{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_variant_data = pd.read_csv('training_variants')\n",
    "X_train_variant_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321\n"
     ]
    }
   ],
   "source": [
    "print X_train_variant_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACSL4</td>\n",
       "      <td>R570S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NAGLU</td>\n",
       "      <td>P521L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAH</td>\n",
       "      <td>L333F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ING1</td>\n",
       "      <td>A148D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TMEM216</td>\n",
       "      <td>G77A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Gene Variation\n",
       "0   0    ACSL4     R570S\n",
       "1   1    NAGLU     P521L\n",
       "2   2      PAH     L333F\n",
       "3   3     ING1     A148D\n",
       "4   4  TMEM216      G77A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_variant_data = pd.read_csv('test_variants')\n",
    "X_test_variant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2. This mutation resulted in a myeloproliferat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract The Large Tumor Suppressor 1 (LATS1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vascular endothelial growth factor receptor (V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Inflammatory myofibroblastic tumor (IMT) is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abstract Retinoblastoma is a pediatric retina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  2. This mutation resulted in a myeloproliferat...\n",
       "1   1   Abstract The Large Tumor Suppressor 1 (LATS1)...\n",
       "2   2  Vascular endothelial growth factor receptor (V...\n",
       "3   3  Inflammatory myofibroblastic tumor (IMT) is a ...\n",
       "4   4   Abstract Retinoblastoma is a pediatric retina..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = pd.read_table('training_text', sep='\\|\\|', engine='python', names=['ID', 'Text'], skiprows=[0])\n",
    "X_test_text = pd.read_table('test_text', sep='\\|\\|', engine='python', names=['ID', 'Text'], skiprows=[0])\n",
    "X_test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996\n"
     ]
    }
   ],
   "source": [
    "print len(np.unique(X_train_variant_data['Variation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Remove the class target label from the training variant data set and add it to an independent target label array\n",
    "\"\"\"\n",
    "y_train = X_train_variant_data['Class']\n",
    "X_train_variant_data.drop('Class', axis=1, inplace=True)\n",
    "y_train.head()\n",
    "#print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class1  class2  class3  class4  class5  class6  class7  class8  class9\n",
       "0       1       0       0       0       0       0       0       0       0\n",
       "1       0       1       0       0       0       0       0       0       0\n",
       "2       0       1       0       0       0       0       0       0       0\n",
       "3       0       0       1       0       0       0       0       0       0\n",
       "4       0       0       0       1       0       0       0       0       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    One hot encode the target label array\n",
    "\"\"\"\n",
    "\n",
    "y_train = pd.get_dummies(y_train, prefix='class', prefix_sep='')\n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 500)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Hash vectorize gene, variation columns\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "X_train_gene = X_train_variant_data['Gene']\n",
    "gene_hash_vectorizer = HashingVectorizer(n_features=500)\n",
    "gene_vector = gene_hash_vectorizer.transform(X_train_gene)\n",
    "\n",
    "X_train_variation = X_train_variant_data['Variation']\n",
    "variation_hash_vectorizer = HashingVectorizer(n_features=5000)\n",
    "variation_vector = variation_hash_vectorizer.transform(X_train_variation)\n",
    "\n",
    "X_test_gene = X_test_variant_data['Gene']\n",
    "gene_test_hash_vectorizer = HashingVectorizer(n_features=500)\n",
    "gene_test_vector = gene_test_hash_vectorizer.transform(X_test_gene)\n",
    "\n",
    "X_test_variation = X_test_variant_data['Variation']\n",
    "variation_test_hash_vectorizer = HashingVectorizer(n_features=5000)\n",
    "variation_test_vector = variation_test_hash_vectorizer.transform(X_test_variation)\n",
    "\n",
    "print gene_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection u'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Download nltk stopwords corpus\n",
    "\"\"\"\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'opinion', u'guarante', u'life']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Process clinical text data by tokenizing words, removing stop words, stemming words etc.\n",
    "\"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import utils\n",
    "def process_clinical_text(clinical_text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_text = word_tokenize(utils.to_unicode(clinical_text))\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    processed_text = []\n",
    "    for word in tokenized_text:\n",
    "        if word not in stop_words:\n",
    "            processed_text.append(stemmer.stem(word))\n",
    "    return processed_text\n",
    "\n",
    "print process_clinical_text('I am of the opinion that there is no guarantee any where in life')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Method to apply doc2vec model on training and test data\n",
    "\"\"\"\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import utils\n",
    "\n",
    "def apply_doc2vec_model(processed_text):\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    epochs = 30\n",
    "\n",
    "    tagged_clinical_text = []\n",
    "\n",
    "    for i, text in processed_text.iteritems():\n",
    "        tagged_clinical_text.append(TaggedDocument(text, ['ct_' + '%s' % str(i)]))\n",
    "\n",
    "    doc2vec_model = Doc2Vec(dm=1, dm_mean=1, min_count=1, window=5, workers=cores, alpha=0.075, min_alpha=0.075)\n",
    "    doc2vec_model.build_vocab(tagged_clinical_text)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        doc2vec_model.train(tagged_clinical_text, total_examples=len(tagged_clinical_text), epochs=1)\n",
    "        doc2vec_model.alpha -= 0.002\n",
    "        doc2vec_model.min_alpha = doc2vec_model.alpha\n",
    "        \n",
    "    #clinical_text_vector = np.zeros((len(tagged_clinical_text), 300))\n",
    "    clinical_text_vector = []\n",
    "    for i in range(len(tagged_clinical_text)):\n",
    "        clinical_text_vector.append(doc2vec_model.docvecs['ct_'+str(i)])\n",
    "    \n",
    "    return clinical_text_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63371795 -2.08129549  0.95111269  1.71817601  2.63506103 -2.56777287\n",
      " -0.71583354  1.54427564 -0.61628222 -1.98483753  0.58251321  1.39327371\n",
      " -1.20367742 -0.77654397 -2.94564128  0.03658156 -1.47104001 -0.31069657\n",
      "  2.56948113  0.99757743 -2.21715307  0.58444571  3.12542439 -0.38942185\n",
      "  1.43385589  1.15081048 -1.07815278 -1.88893485 -0.1088432  -0.46550974\n",
      " -0.08182781  0.48247933  0.35739917  0.64795667 -0.20882474  1.8862108\n",
      " -1.1752615   0.28705853 -0.37376478  0.73973131  0.81681758  0.03721907\n",
      "  0.21466365  1.01701999 -1.22662497  2.68129873 -1.24904776 -0.14178559\n",
      "  1.19746399 -0.05019539  0.36976475  1.54917681  3.74929738  1.31612742\n",
      " -0.27364281  0.16332625  1.37771857  0.62415457  0.82757509  1.66925657\n",
      " -0.69641745  0.81700134  1.67378223  1.57470536  0.7599265   2.1202774\n",
      "  0.08763322 -2.02270699  0.2476923  -0.07333846  0.72233593 -0.53051513\n",
      " -2.15938902  0.22358432 -0.23433346  0.94078761 -1.35449624  1.72819126\n",
      "  1.57680023  3.11409569 -1.30927372 -1.33008981 -2.18830538 -0.70090008\n",
      " -1.68554485 -2.30801225 -1.27444935  1.08930528 -1.009709   -1.10499334\n",
      "  0.61081725  1.18794286 -1.47185147 -2.0543201   0.51600868  0.08682162\n",
      " -2.54555035 -0.40310279 -2.01007891 -2.49580979]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Apply Doc2Vec model on the clinical text training and test data\n",
    "\"\"\"\n",
    "\n",
    "processed_clinical_text = X_train_text['Text'].apply(process_clinical_text)\n",
    "#print processed_clinical_text[0]\n",
    "clinical_text_train = apply_doc2vec_model(processed_clinical_text)\n",
    "#print clinical_text_train[0]\n",
    "processed_clinical_test_text = X_test_text['Text'].apply(process_clinical_text)\n",
    "clinical_text_test = apply_doc2vec_model(processed_clinical_test_text)\n",
    "print clinical_text_test[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print clinical_text_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 5600)\n",
      "(3321, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Combine gene vector, variation vector and clinical text vector into a resultant training set\n",
    "\"\"\"\n",
    "\n",
    "X_train = np.hstack((gene_vector.toarray(), variation_vector.toarray(), clinical_text_train))\n",
    "X_test = np.hstack((gene_test_vector.toarray(), variation_test_vector.toarray(), clinical_text_test))\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 5600, 1)\n",
      "(3321, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Expand dimensions of data to fit into the CNN model\n",
    "\"\"\"\n",
    "\n",
    "X_train_dim_data = np.expand_dims(X_train, axis=2)\n",
    "print X_train_dim_data.shape\n",
    "y_train_dim_data = np.array(y_train)\n",
    "print y_train_dim_data.shape\n",
    "\n",
    "X_test_dim_data = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Define and compile the CNN model\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_cnn_model(optimizer='rmsprop'):\n",
    "    num_classes = 9\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=X_train_dim_data.shape[1:]))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(GlobalAveragePooling1D())\n",
    "    cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 5600, 16)          48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2800, 32)          1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1400, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 5,849\n",
      "Trainable params: 5,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f44220521d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Define and compile the CNN model\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_cnn_model2(optimizer='rmsprop'):\n",
    "    num_classes = 9\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=16, kernel_size=5, padding='same', activation='relu', input_shape=X_train_dim_data.shape[1:]))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 9)\n",
      "[1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Reshape the training inputs for KFold cross validation inputs\n",
    "\"\"\"\n",
    "X_train_2d = X_train_dim_data.reshape(X_train_dim_data.shape[0], X_train_dim_data.shape[1])\n",
    "y_train_2d = y_train_dim_data.reshape(y_train_dim_data.shape[0], y_train_dim_data.shape[1])\n",
    "print y_train_2d.shape\n",
    "print y_train_2d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 5600, 16)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2800, 32)          2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1400, 64)          10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 44800)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               5734528   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 5,748,681\n",
      "Trainable params: 5,748,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2988 samples, validate on 333 samples\n",
      "Epoch 1/1\n",
      "2980/2988 [============================>.] - ETA: 0s - loss: 1.8324 - acc: 0.3023Epoch 00000: val_loss improved from inf to 1.91503, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2988/2988 [==============================] - 8s - loss: 1.8342 - acc: 0.3029 - val_loss: 1.9150 - val_acc: 0.3483\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 1.4274 - acc: 0.5087Epoch 00000: val_loss improved from 1.91503 to 1.61043, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 5s - loss: 1.4277 - acc: 0.5085 - val_loss: 1.6104 - val_acc: 0.3946\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 1.1797 - acc: 0.5755Epoch 00000: val_loss improved from 1.61043 to 1.08057, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 1.1798 - acc: 0.5758 - val_loss: 1.0806 - val_acc: 0.6807\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 1.0200 - acc: 0.6470Epoch 00000: val_loss improved from 1.08057 to 1.01719, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 1.0216 - acc: 0.6467 - val_loss: 1.0172 - val_acc: 0.6024\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.8764 - acc: 0.6940Epoch 00000: val_loss improved from 1.01719 to 0.97950, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 0.8776 - acc: 0.6939 - val_loss: 0.9795 - val_acc: 0.6446\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.7816 - acc: 0.7312Epoch 00000: val_loss improved from 0.97950 to 0.73578, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 0.7806 - acc: 0.7317 - val_loss: 0.7358 - val_acc: 0.7259\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.7079 - acc: 0.7483Epoch 00000: val_loss improved from 0.73578 to 0.50876, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 0.7068 - acc: 0.7487 - val_loss: 0.5088 - val_acc: 0.8223\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.7899Epoch 00000: val_loss did not improve\n",
      "2989/2989 [==============================] - 4s - loss: 0.6110 - acc: 0.7896 - val_loss: 0.6909 - val_acc: 0.7620\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.5552 - acc: 0.7973Epoch 00000: val_loss improved from 0.50876 to 0.34754, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "2989/2989 [==============================] - 4s - loss: 0.5546 - acc: 0.7976 - val_loss: 0.3475 - val_acc: 0.8855\n",
      "Train on 2989 samples, validate on 332 samples\n",
      "Epoch 1/1\n",
      "2980/2989 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8362Epoch 00000: val_loss did not improve\n",
      "2989/2989 [==============================] - 4s - loss: 0.4711 - acc: 0.8367 - val_loss: 0.4650 - val_acc: 0.8494\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Train the CNN model\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "cv_fold = KFold(n_splits=10)\n",
    "cnn_model = create_cnn_model2()\n",
    "\n",
    "for train_index, test_index in cv_fold.split(X_train_2d):\n",
    "    X_fold_train, X_fold_test = X_train_2d[train_index], X_train_2d[test_index]\n",
    "    y_fold_train, y_fold_test = y_train_2d[train_index], y_train_2d[test_index]\n",
    "    X_fold_train = np.expand_dims(X_fold_train, axis=2)\n",
    "    X_fold_test = np.expand_dims(X_fold_test, axis=2)    \n",
    "    cnn_model.fit(X_fold_train, y_fold_train, validation_data=(X_fold_test, y_fold_test), epochs=1, batch_size=20, \n",
    "              callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 5600, 16)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2800, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2800, 32)          2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1400, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1400, 64)          10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 700, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 44800)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               5734528   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 5,748,681\n",
      "Trainable params: 5,748,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(3321, 5600)\n",
      "(3021, 5600)\n",
      "Train on 3021 samples, validate on 300 samples\n",
      "Epoch 1/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.8040 - acc: 0.3172Epoch 00000: val_loss improved from inf to 1.87767, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "3021/3021 [==============================] - 5s - loss: 1.8041 - acc: 0.3171 - val_loss: 1.8777 - val_acc: 0.2100\n",
      "Epoch 2/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.3202 - acc: 0.5397Epoch 00001: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 1.3198 - acc: 0.5399 - val_loss: 1.9866 - val_acc: 0.3033\n",
      "Epoch 3/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.0895 - acc: 0.6093Epoch 00002: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 1.0900 - acc: 0.6091 - val_loss: 1.9476 - val_acc: 0.2567\n",
      "Epoch 4/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.9515 - acc: 0.6646Epoch 00003: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.9517 - acc: 0.6643 - val_loss: 2.0344 - val_acc: 0.3367\n",
      "Epoch 5/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.8326 - acc: 0.6987Epoch 00004: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.8324 - acc: 0.6988 - val_loss: 2.2448 - val_acc: 0.3667\n",
      "Epoch 6/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.7351 - acc: 0.7381Epoch 00005: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.7354 - acc: 0.7378 - val_loss: 2.2827 - val_acc: 0.3267\n",
      "Epoch 7/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.7695Epoch 00006: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.6403 - acc: 0.7696 - val_loss: 2.7405 - val_acc: 0.2933\n",
      "Epoch 8/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.5829 - acc: 0.7901Epoch 00007: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.5829 - acc: 0.7901 - val_loss: 3.0171 - val_acc: 0.2900\n",
      "Epoch 9/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.5094 - acc: 0.8205Epoch 00008: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.5095 - acc: 0.8206 - val_loss: 3.1951 - val_acc: 0.3000\n",
      "Epoch 10/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8460- ETA: 1s - loss: 0.4Epoch 00009: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.4381 - acc: 0.8461 - val_loss: 3.2054 - val_acc: 0.3267\n",
      "Epoch 11/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.8649Epoch 00010: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.3794 - acc: 0.8649 - val_loss: 3.4942 - val_acc: 0.3433\n",
      "Epoch 12/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.8914Epoch 00011: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.3188 - acc: 0.8914 - val_loss: 3.6160 - val_acc: 0.3067\n",
      "Epoch 13/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.2880 - acc: 0.9043Epoch 00012: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.2879 - acc: 0.9043 - val_loss: 4.1506 - val_acc: 0.2800\n",
      "Epoch 14/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9113Epoch 00013: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.2514 - acc: 0.9113 - val_loss: 4.1374 - val_acc: 0.2733\n",
      "Epoch 15/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9305Epoch 00014: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.2006 - acc: 0.9305 - val_loss: 4.5496 - val_acc: 0.2767\n",
      "Epoch 16/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9437Epoch 00015: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.1836 - acc: 0.9437 - val_loss: 4.9301 - val_acc: 0.2700\n",
      "Epoch 17/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9483Epoch 00016: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.1585 - acc: 0.9484 - val_loss: 4.9021 - val_acc: 0.2800\n",
      "Epoch 18/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9530Epoch 00017: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.1236 - acc: 0.9530 - val_loss: 5.0586 - val_acc: 0.2600\n",
      "Epoch 19/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9632Epoch 00018: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.1135 - acc: 0.9633 - val_loss: 5.4983 - val_acc: 0.2733\n",
      "Epoch 20/20\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9722Epoch 00019: val_loss did not improve\n",
      "3021/3021 [==============================] - 4s - loss: 0.0882 - acc: 0.9722 - val_loss: 5.5740 - val_acc: 0.2733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43dbd96950>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Train the CNN model 2\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "cnn_model = create_cnn_model2()\n",
    "X_valid_test = X_train_2d[:300]\n",
    "y_valid_test = y_train_2d[:300]\n",
    "X_train = X_train_2d[300:]\n",
    "y_train = y_train_2d[300:]\n",
    "\n",
    "print X_train_2d.shape\n",
    "print X_train.shape\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid_test = np.expand_dims(X_valid_test, axis=2)\n",
    "cnn_model.fit(X_train, y_train, validation_data=(X_valid_test, y_valid_test), epochs=20, batch_size=20, \n",
    "        callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Load the best weights into the model\n",
    "\"\"\"\n",
    "cnn_model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668/5668 [==============================] - 1s     \n",
      "[ 0.08427842  0.23235247  0.04952785  0.16867645  0.08345897  0.08399524\n",
      "  0.26397043  0.01666131  0.01707882]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Make predictions from test data\n",
    "\"\"\"\n",
    "\n",
    "model_predictions = cnn_model.predict_proba(X_test_dim_data)\n",
    "\n",
    "print model_predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(model_predictions)):\n",
    "    max_value = model_predictions[i][np.argmax(model_predictions[i])]\n",
    "    y_pred.append(model_predictions[i] // max_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print y_pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[1, 2, 2, 4, 4, 4, 9, 7, 7, 7, 2, 1, 4, 1, 1, 1, 2, 3, 2, 7, 2, 1, 7, 7, 3, 7, 9, 7, 1, 4, 1, 6, 4, 9, 6, 4, 1, 5, 2, 1, 3, 2, 7, 7, 5, 7, 4, 6, 4, 1, 1, 4, 7, 1, 6, 7, 1, 1, 7, 2, 7, 2, 1, 7, 4, 9, 7, 4, 4, 1, 4, 5, 1, 1, 1, 4, 2, 2, 1, 7, 1, 5, 6, 7, 6, 6, 1, 7, 5, 2, 1, 4, 7, 7, 4, 1, 1, 4, 7, 1, 1, 2, 3, 7, 2, 2, 7, 4, 1, 4, 4, 7, 4, 7, 7, 7, 6, 3, 7, 7, 4, 4, 4, 2, 4, 1, 4, 1, 4, 1, 2, 4, 7, 7, 4, 7, 7, 7, 4, 1, 2, 7, 4, 1, 1, 7, 2, 7, 7, 7, 2, 2, 1, 4, 1, 1, 7, 7, 1, 5, 4, 4, 7, 2, 1, 2, 4, 6, 4, 7, 1, 1, 1, 1, 7, 7, 4, 5, 4, 1, 4, 2, 6, 7, 4, 5, 7, 3, 1, 7, 6, 2, 1, 8, 7, 7, 5, 7, 5, 5, 1, 1, 1, 7, 7, 2, 1, 1, 7, 1, 2, 1, 4, 9, 1, 2, 7, 7, 1, 2, 4, 1, 4, 7, 7, 1, 4, 8, 4, 5, 4, 4, 5, 1, 4, 1, 2, 7, 2, 4, 1, 6, 6, 5, 7, 7, 6, 2, 7, 9, 1, 1, 2, 6, 7, 7, 7, 1, 1, 1, 4, 5, 7, 7, 7, 2, 5, 7, 1, 6, 7, 1, 5, 5, 6, 7, 2, 1, 2, 4, 2, 7, 7, 4, 1, 5, 7, 2, 5, 6, 4, 5, 7, 5, 7, 7, 1, 7, 7, 5, 7, 3, 2, 1, 7, 6, 7, 7, 4, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 1, 2, 4, 1, 4, 4, 7, 2, 1, 1, 7, 2, 1, 1, 6, 7, 1, 6, 7, 4, 7, 7, 7, 4, 1, 7, 1, 1, 7, 1, 4, 7, 5, 2, 7, 7, 2, 7, 7, 1, 7, 4, 2, 4, 4, 6, 4, 1]\n",
      "368\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Kaggle competition test data set for target class labels are incomplete and as such our test prediction \n",
    "    and true values need to be reconciled appropriately\n",
    "\"\"\"\n",
    "y_true_data = pd.read_csv('stage1_solution_filtered.csv')\n",
    "\n",
    "y_final_pred = [y_pred[d] for d in y_true_data['ID']]\n",
    "model_predictions_final = [model_predictions[d] for d in y_true_data['ID']]\n",
    "\n",
    "y_final_pred_labels = [ np.argmax(pred) + 1 for pred in y_final_pred]\n",
    "print y_final_pred_labels[0]\n",
    "\n",
    "y_true_data.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "y_true_data_labels = [np.argmax(data) + 1 for data in np.array(y_true_data)]\n",
    "print y_true_data_labels\n",
    "\n",
    "print len(y_final_pred_labels)\n",
    "print len(y_true_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.66870468563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "#print model_predictions_final\n",
    "\n",
    "#print log_loss(y_true_data_labels, model_predictions_final)\n",
    "print log_loss(np.array(y_true_data), model_predictions_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXecVNX5h593C32pS28iZQGR3pQiiiJdNGJANIgUNRBr\n4k+NiSUaazQmtqBGUewFKwhIsSDSe1EERZr0XneX9/fHvUvGFXZmdu6dnbv7Pn7uZ2funPmeM3eG\n13POPef9iqpiGIYRZJIKugGGYRixYoHMMIzAY4HMMIzAY4HMMIzAY4HMMIzAY4HMMIzAY4GskCEi\nJUXkIxHZKyJvx6AzRESmeNm2gkBEJonI0IJuh+EvFsgKCBG5XETmi8gBEdni/oPr7IH0pUBVoJKq\nDsyviKq+qqo9PGjPLxCRbiKiIjIh1/kW7vmZEercLSLjw5VT1V6qOi6fzTUCggWyAkBEbgb+Cfwd\nJ+jUAZ4GLvJAvi7wnapmeaDlF9uBs0SkUsi5ocB3XlUgDvb7Liqoqh1xPIBywAFgYB5liuMEus3u\n8U+guPtaN2AjcAuwDdgCDHNfuwc4BmS6dQwH7gbGh2ifBiiQ4j6/ClgH7Ad+AIaEnP8q5H1nA/OA\nve7fs0Nemwn8DZjl6kwB0k/x2XLa/yww2j2XDGwC/grMDCn7BLAB2AcsALq453vm+pxLQtpxv9uO\nw0AD99wI9/VngHdD9B8CpgFS0L8LO2I77P9Y8ecsoAQwIY8yfwY6Ai2BFkB74M6Q16vhBMSaOMHq\nKRGpoKp34fTy3lTVMqr6Ql4NEZHSwL+AXqqahhOsFp+kXEXgE7dsJeAx4JNcParLgWFAFaAY8Me8\n6gZeBn7nPr4QWI4TtEOZh3MNKgKvAW+LSAlV/TTX52wR8p4rgVFAGrA+l94twJkicpWIdMG5dkPV\njWpGcLFAFn8qATs076HfEOBeVd2mqttxelpXhrye6b6eqaoTcXolGflsz3GgmYiUVNUtqrriJGX6\nAGtU9RVVzVLV14HVQL+QMi+q6neqehh4CycAnRJV/RqoKCIZOAHt5ZOUGa+qO906/4HTUw33OV9S\n1RXuezJz6R3CuY6PAeOBP6jqxjB6RgCwQBZ/dgLpIpKSR5ka/LI3sd49d0IjVyA8BJSJtiGqehD4\nLXAtsEVEPhGRxhG0J6dNNUOe/5yP9rwCjAHO5SQ9VBH5o4iscu/A7sHphaaH0dyQ14uqOgdnKC04\nAdcoBFggiz+zgaPAgDzKbMaZtM+hDr8edkXKQaBUyPNqoS+q6mRVvQCojtPLei6C9uS0aVM+25TD\nK8DvgYlub+kE7tDvVuAyoIKqlseZn5Ocpp9CM89hooiMxunZbXb1jUKABbI4o6p7cSa1nxKRASJS\nSkRSRaSXiDzsFnsduFNEKotIuls+7FKDU7AY6CoidUSkHHB7zgsiUlVELnLnyo7iDFGPn0RjItDI\nXTKSIiK/BZoCH+ezTQCo6g/AOThzgrlJA7Jw7nCmiMhfgbIhr28FTovmzqSINALuA67AGWLeKiJ5\nDoGNYGCBrABw53tuxpnA344zHBoDvO8WuQ+YDywFlgEL3XP5qWsq8KartYBfBp8ktx2bgV04QeW6\nk2jsBPriTJbvxOnJ9FXVHflpUy7tr1T1ZL3NycCnOEsy1gNH+OWwMWex704RWRiuHncoPx54SFWX\nqOoa4A7gFREpHstnMAoesRs2hmEEHeuRGYYReCyQGYYReCyQGYYReCyQGYYRePJalBl3SperqBWq\n1QxfMEGpWsb/m1/rdx/2Vb9uhZK+6mf7fHMpK9v/m1fFU4L7///1639kx44dEr7kqUkuW1c1K7Lf\noR7ePllVe8ZSXyQkVCCrUK0mY555P3zBBOXGrvV9r+O6t5f6qv/MwOa+6u87nBm+UAzsPuivPkDd\n9FLhCyUonTq0jVlDsw5TPOOyiMoeWfxUuJ0YnpBQgcwwjCAgkGAZkiyQGYYRHQIkJRd0K36BBTLD\nMKJHYppm8xwLZIZhRIkNLQ3DKAxYj8wwjEAjJFyPLLFacwr2bNvMczcP4fFhF/L41T2Z9e5LAHw2\n7gkeuKwT/xrVj3+N6sfqOTMTUj83UyZ/SvMzMjijcQMeefhBTzRTkoS/9GjAPT0bcl/vRgxoVhWA\n7g0r8WDfDF4c3JwyxbyboPXjM+QmOzub7p3bMWRgXqnb8sfLzz1Fv25t6XtOW8aNfdJzfb+vTzyu\n/6kRp0cWyREnfOuRich/cVK/bFPVZrFoJSWn0Pva26nZqBlHDx3g39cOoEGbTgB0unQYXS8bEVNb\n/dYPJTs7mxuvH80nk6ZSs1YtOndsR9++/WnStGlMulnHlYenr+No1nGSBW4/vwFLt+xnzY6DLN68\nj9vO826Nm1+fITfPPfNvGjZqzP79+z3V/W71Ct5+9UXemvgFqcWKMfLyi+h2QS/q1vPmGvl9feJ1\n/fMkwe5a+tkjewnH7SZmylaqQs1GTiwsXqoMVerWZ9+OrV5Ix0U/lHlz51K/fgPqnX46xYoVY+Bv\nB/HxRx94on00y8mJmJwkpCQJoPy0+wg7PV4k6udnyGHzpo1MnTyJIUOv9lQXYN2ab2neuh0lS5Ui\nJSWFdh27MHWid+33+/rE4/rnjTvZH8kRJ3yrSVW/wEnW5ym7f97I5u9XUruJY5wz+/1XeGJEH955\n5DYO79+b8PqbN2+iVq3aJ57XrFmLTZtizRjtIAL39GzIExc3ZcXP+1m305/tTH5+hhz+ctst/PXe\nB0hK8v4n2jCjKfPnfM3uXTs5fOgQn0+fzJbN3rXf7+sTj+ufJ0LCDS0LfI5MREa5jtvzD+7JO+4d\nPXyQ8XePpu/v76RE6TQ69BvCn16Zzh/GfkRaxcp88uwDMbXFb32/UYW7Pl3DzR+sol6lUtQsF8zE\np1MmfUJ6ehVatGrti379Ro0ZOfpmhg/qz8jLB9DkjOYk+xAwCzVFpUcWKao6VlXbqmrb0uUrnrJc\ndlYmr949mpbd+9Osy4UApFVMJyk5maSkJNr3+S0bVy/Jdzv81s+hRo2abNz4v4zNmzZtpGZNbzfK\nH848zuqtBzizepqnujn4/RnmzvmayZM+pm2zhlwz7ApmfTGD348Y6pk+wKWXD+W9KbMY//4UypYr\nz2n1G3qm7ff1icdvKG+K0NDSS1SVdx+9ncp1GtBl4PAT5/ft3Hbi8YqvplD1tEYJqR9K23bt+P77\nNfz4ww8cO3aMt998gz59+8esm1Y8mZKpzteZmiycUS2NLfuOxqx7Mvz6DDnceff9LF79A/OXr+E/\nL46nU9dzefr5cZ7pA+zc4Xy3mzduYOrED+l7cWSboCPB7+vjt35YBEhOjuyIE4FYR7Z++QIWTX2f\navUy+NcoxxO2x/BbWDL9I7asXYUgVKhWkwE35cufw3f9UFJSUnj8iSfp1+dCsrOzGXrV1TQ944yY\ndcuVTGVEx9okCQjCvJ/2sGTzfs5vVIleTSpTrkQq9/ZqxLIt+3lxbmyetH59hnhy/fAh7Nm9i5TU\nFP76wGOULVfeM22/r09CXP8EWxDrm/mIiLwOdMMxVN0K3KWqL+T1nloZZ6ql8ckbS+OTN5bGJ286\ndWjLggXzY4pCSWVrafH2YyIqe2Ta7QtUNfbcQWHwrUemqoP90jYMo4BJsB5ZIIaWhmEkGAm2RckC\nmWEY0RHnNWKRYIHMMIzoSbAtShbIDMOIEstHZhhGYcCGloZhBJoEzEeWUIGsapnivq7Fuvr1xb5p\nx4u7Loh9d0FBUsrDnGgn42jmcV/1DbChpWEYhQOb7DcMI/DYHJlhGIFGvBtaisiPwH4gG8hS1bYi\nUhF4EzgN+BG4TFV356WTWANdwzCCgbeJFc9V1ZYhezJvA6apakNgmvs8TyyQGYYRNSIS0ZFPLgJy\n8jaNA8K6z1ggMwwjKpxM1xEHsvScDNDuMSqXnAJTRGRByGtVVXWL+/hnoGq4NtkcmWEY0SGCJEXc\n29oRJo1PZ1XdJCJVgKkisjr0RVVVEQmbayyQPTKvPf1Sk4S/9WrIA30yeLhfBr9pXg2A0Z3r8Gj/\nxjzUL4NRZ9Um2aMbNX57Eq79/jt6d+tw4jizXhX+++y/Pa3Dz89w3ajh1Ktdjfat/cuNtnfvHq65\najDndmjOeR1bsGDeN57qF25fS++Glqq6yf27DZgAtAe2ikh1t57qwLZTKzj4FshEpLaIzBCRlSKy\nQkRu8EI3x9Pvg48msWjpSt5+43VWrVwZk2bmceW+qWu5/ZNvuf3jb2lRM40G6aWYtW43f/xwNf/3\n0bcUS07i3IaVErL9uanfoBETZ85h4sw5fDTta0qULEWPPt6lQvb7Mwy5cigTPpzomd7JuPv2W+jW\n/QJmzFnKp1/Mo0Gjxp5p+3194vEbCocXgUxESotIWs5joAewHPgQyDFpGAqE9brzs0eWBdyiqk2B\njsBoEYnZQdQvT79QT8hkERRYvPl/xrBrdx6iYqnUmOuJtyfhrC9mUPe0etSqXdczTb8/Q+cuXalQ\n4dRGNLGyb99e5s7+ikFXDAOgWLFilPMw1XXh97X0rEdWFfhKRJYAc4FPVPVT4EHgAhFZA5zvPs8T\nP30tt6jqQvfxfmAVELPVi1+efiLw9z4ZPDuwGcu27GftjkMnXksW6FyvAks2x+54HW9Pwo8nvE2/\nS7wz1oAE8FWMkQ3rf6RipcrcMmYkvbp14NYbruXQwYOe6RcNX8sIjzxQ1XWq2sI9zlDV+93zO1W1\nu6o2VNXzVTWsP25c5shE5DSgFTAnHvXlB1W445NvGfPuSuqnl6JW+RInXhvWoTartx3k223e/djj\nwbFjx/hs8if07n9JQTclocjKymL50kVcOWwUk2bOoWSp0jz9xCMF3azAIETWG4th+UXU+B7IRKQM\n8C5wo6ruO8nrJwx6t+/YHlbPb0+/Q5nZrPz5AC1qOJ6QlzSvStkSKYyf783/8eLpSThz2mTOaN6S\nylXC3r2OioL3VYyN6jVqUr1GTVq1bQ9A7/4Xs3ypdwkFCr+vJSQlJUV0xK09foqLSCpOEHtVVd87\nWZlQg97K6ZXDavrh6ZdWPJlSqc4m2NRk4czqaWzee5RuDSrSvHpZ/v3lj3jlNRVPT8KP3nuL/h76\nNeZQ4L6KMVKlajWq16zF2jXfAc48YsOMJp7pF3pfS3xfEBs1vq0jE+dTvACsUtXHvNL1w9OvfMlU\nrutUhyQRROCbH/ewaNM+XhnSgh0Hj3FPTyd1zryf9jBh2daEa//JOHTwIF99Pp37//Gk59p+f4Zh\nV17Ol19+zs4dO8ioX4c77ryLocOGh39jFNz74ONcf81VZGYeo07dejz65FjPtAu9r2UE81/xxk9f\ny87Al8AyICdJ1B2qesr76m3atNVZc+b70h7wPx/Zfwe39FUf4Oc9R3zVrxYyN+gHWdn+5guLh69l\n5bLFfa/DL7zwtUxJP13L9/17RGV3jhsceF/Lr0i4uG0YRqzkTPYnErZFyTCMqIlii1JcsEBmGEZ0\nCNYjMwwj+FggMwwj8FggMwwj0Nhkv2EYhYPEimNFK5A92i/m5BsFTnpasYJuQkykJPu7baVC6dgz\nlBhhEOK6/SgSilQgMwzDG2xoaRhG8EmsOGaBzDCM6LEemWEYgSbemS0iwQKZYRhRY4HMMIzAY3st\nDcMIPNYjMwwj2CTgpvHEWtUWIX6bk3Zo3ojuZ7fmgi7t6HXuWZ7r+93+eBjcBt2A1u9rFPTrkxeC\n4zoWyREv/DToLSEic0VkiWvQe48XuvEyJ337oylM/XIek2bM9lQ3Hu332+C2MBjQ+nmNCsP1yZui\n5aJ0FDhPVVsALYGeItIxVtFEMCeNhXi032+D28JgQOvnNSoM1yccSUkS0RG39vglrA4H3Kep7hGz\nQUA8zElFYPAlfejZrSPjX3reU+0CN1f1gEJvQBsjhf76RDisjOfQ0tfJfhFJBhYADYCnVPVXBr0i\nMgoYBVC7Th0/mxMxEybNoHqNmuzYvo1BF/emQcMMOnbqUtDNMoyEQCCuva1I8HWyX1WzVbUlUAto\nLyLNTlImKl/LeJiTVq/h6KVXrkKvvhexeOE8z7QTwVw1VoqCAW0sFIXrk2g9srjctVTVPcAMoGes\nWn6bkx46eJAD+/efePz59M/IaOKdZ2AimKvGSlEwoI2FonB9Em2y30+D3spApqruEZGSwAXAQ7Hq\n+m1Oun37VoZf4bhzZ2dnMeA3gzj3/As904+HuarfBreFwYDWz2tUGK5PnsS5txUJfhr0NgfGAck4\nPb+3VPXevN7jt0HvrgPHfNMGqFjG/6SHfhvc+p340G/8vj4Q7GvkhUFvqRoZ2nDk0xGVXXrv+WEN\net259PnAJlXtKyL1gDeASjhz7Feqap7/eP28a7lUVVupanNVbRYuiBmGERw8niO7AVgV8vwh4HFV\nbQDsBsJ2lYP7vxbDMAoMr+bIRKQW0Ad43n0uwHnAO26RccCAcDq219IwjOiIrreVLiKh80VjVXVs\nyPN/ArcCae7zSsAeVc1yn28Ewt6StUBmGEZUOHstI45kO041RyYifYFtqrpARLrF0iYLZIZhRI1H\ndy07Af1FpDdQAigLPAGUF5EUt1dWCwi7bcHmyAzDiBov9lqq6u2qWktVTwMGAdNVdQjOmtNL3WJD\ngbAbSS2QGYYRHeL7gtj/A24Wke9x5sxeCPeGhBpaKv6uA/r25/2+aQOc1aCSr/oAfZ72Nq1Qbib/\noZOv+n6v81q/45Cv+gD1q5bxvY5EJicfmZeo6kxgpvt4HdA+mvcnVCAzDCMImIuSYRiFgASLYxbI\nDMOIEkm8ND4WyAzDiIoo15HFBQtkhmFEjQUywzACT4LFMQtkhmFET6L1yAK5INYPT8KH/3w9l3Rq\nzNX9Ov/i/Hvjn2No744M69uJ/zxytyd1+eFJWCxZeHZwc164oiUv/a4Vw85yzCn+fVkznh/SgueH\ntODdke24r19jT+rz01fRj+/3zluuo2uLegzo/r/lSXt372LE4P707tySEYP7s3fPbs/qK8y+lolo\nPuJ7IBORZBFZJCIfe6XphyfhhQMG8eDYN39xbtGcL/l62iSee/9zXvx4FpddPTrmevzyJDyWrdz0\nznKGj1/M8PGLaV+3Ak2rleEPby1nxKtLGPHqElZs2ceX3+9M2M+Qgx/f74CBQ3h2/IRfnHv+qcfo\n2OkcJn61mI6dzuGFpx7zpK7C7mspRLY9qVDYwYWQO2lazPjhSdii3dmULV/hF+c+fOMlBo+8gWLF\nigNQoVJ4c5Rw+OlJeDjTWTWfkiSkJMkvvPdKFUumde3yfLl2V8z1+O2r6Mf327ZjZ8rl+n5nTPmE\niwYOAeCigUOYPtmb/9cWCV9LkYiOuLXHT/HcSdOCxsYf17JswWx+/9se3HhlP1YvWxizpp+ehEkC\nzw9pwfvXtGf+T3tY9fOBE691qV+RBRv2cOhYdsz1FLivokfs3LGdylWrAZBepSo7d2z3RLfQ+1pS\n9IaWOUnTTrnBTkRGich8EZm/Y7s3PySvyM7KYt/ePTz1xmSu+dM93HvTCPzyOPCC4wojXl3CwOfn\n0aRaGvUqlTrxWveMykxbvaMAW5fYxNv1J8iI/5vGo+aUgUxEyuZ1hBMOTZqWV7lQX8v0yrEP3byk\ncrUadLmgDyJCk+atkaQk9u6ObY4pHp6EB45ms2jDXtqfVh6AciVSaFytDN/8EPuwEhLDV9ELKqVX\nZvvWnwHYvvVnKlZK90S3KPhaJklkR9zak8drK4Dl7t8VuZ4vj0A7J2najziOKOeJyPiYWhtnOnXv\nxeI5XwGw4Yfvyco8RrkKsWW48MuTsFzJFMoUTwagWHISbeuW46ddhwE4p1E6s3/YzbFsb3qTieCr\n6AXdLujNB2+/CsAHb7/KuT36eKJbFHwtE22y/5TryFS19qleiwRVvR24HcBNY/tHVb0iFs0c/PAk\n/NstI1kydxZ79+zism5nctWY/6PXJUN45M7rubpfZ1JSU/m/B56MubvslydhpdLFuOPChiSJIAIz\nv9vJ7B+c5QTnNUrntXkbY64jB799Ff34fv80ehjzZn/Jnl076d42g9/fcgcjxtzMLdcO5b03XqFG\nrdr845lxnrS/sPtaCs6dy0QiIl9LERkEnK6qf3cn8KuGGzLmen83nEDWN69yrdu01S++nhupbNTM\n+8G7dUInIx75yC789yxf9S0fWXiCnI/MC1/L8nWbaNc/vxxR2Y+uaR/W19ILwk72i8iTwLnAle6p\nQ8Cz0VSiqjPDBTHDMAJChBP98Zzsj2SL0tmq2lpEFgGo6i4R8d9S2zCMhCXRbvBGEsgyRSQJJxM1\nIlKJPJZTGIZRuBGI62LXSIgkkD0FvAtUFpF7gMuAe3xtlWEYCU3gEiuq6ssisgA43z01UFUjWX5h\nGEYhJN6r9iMh0jQ+yUAmzvAykBkzDMPwjkQbWkZy1/LPwOtADRzX39dE5Ha/G2YYRuIiER7xIpIe\n2e+AVqp6CEBE7gcWAQ943RgBUpL96/DVKF/SN+14cXcvb/KJFRR+fr8Q7DVeQSLR9qVGEsi25CqX\n4p4zDKMI4ty1LOhW/JJTBjIReRxnTmwXsEJEJrvPewDz4tM8wzASDonvPspIyKtHlnNncgXwScj5\nb/xrjmEYQSAwQ0tVfSGeDTEMIxgEamiZg4jUB+4HmgIlcs6raiMf22UYRgLjRY9MREoAXwDFcWLR\nO6p6l4jUw0n9VQlYAFypqsfy0orkFtJLwIs4gbgX8BbwZl5vMAyjcOPR8oujwHmq2gJoCfQUkY7A\nQ8DjqtoA2A2EzeEUSSArpaqTAVR1rareiRPQDMMogohAcpJEdOSFOuQYS6S6hwLnAe+458cBA8K1\nKZJAdtTdNL5WRK4VkX5AWgTv8w2/Pf1efu4p+nVrS99z2jJu7JOe6/vR/nj6ckLwfRtNPzaiSOOT\nnuPJ4R6jcukki8hiYBswFVgL7FHVLLfIRiBsHu9IAtlNQGngepz01SOBqyP8sD+KyDIRWSwi8yN5\nTzj89vT7bvUK3n71Rd6a+AXvT/uGmZ9NYv0Paz3T96v98fLlhOD7Npp+7EThorQjx5PDPcaG6qhq\ntqq2xNk11B7I14rvsIFMVeeo6n5V/UlVr1TV/qoaTZrSc1W1pVdZIv329Fu35luat25HyVKlSElJ\noV3HLkydmPiehPHy5YTg+zaafmwIkXlaRrMfU1X3ADOAs4DyIpJzI7IWENbrLi8XpQki8t6pjohb\n6DF+e/o1zGjK/Dlfs3vXTg4fOsTn0yezZXMwPQn98OWE4Ps2mn6MRNgbCxfHRKSyiJR3H5cELsAx\n854BXOoWGwqEjdJ5Lb/wYnJIgSkiosB/cncrwfG1BEYB1K5Tx4MqY6N+o8aMHH0zwwf1p1Sp0jQ5\noznJScFM+BHqy7l62SLuvWkEr05dkHCLGY3g4dFvqDowTkSScTpVb6nqxyKyEnhDRO7D2dcddk1r\nXgtip3nQ0M6quklEqgBTRWS1qn6Rq56xwFiANm3ahnVCiYen36WXD+XSy4cC8Njf76JajWB6Ep7K\nl7N8xdj8G4Pu22j6sSFAsgeBTFWXAq1Ocn4dznxZxPja1VDVTe7fbcAEomzcyYiHp9/OHdsA2Lxx\nA1Mnfkjfiy/zTDuenoR++HJC8H0bTT92Es2gN9LEilEjIqWBJFXd7z7uAdwbq248PP2uHz6EPbt3\nkZKawl8feIyy5cp7pu1X++Ply+nnZzD9xNCPhETbohSRryWAiBRX1aMRC4ucjtMLAydgvqaq9+f1\nnjZt2uqsOZ6s0jgpfnse1k0v5as+wOzvd/qqHw9vTqPg8MLXslrDZjrksXcjKvtY/8Zx8bWMZK9l\ne5zJtnJAHRFpAYxQ1T/k9T53nNvCk1YahpFQJFqPLJI5sn8BfYGdAKq6BMew1zCMIooXyy+8JJI5\nsiRVXZ9rbiXbp/YYhpHgCJCSYEt4IglkG9zhpbrrPf4AfOdvswzDSGQSLI5FFMiuwxle1gG2Ap+5\n5wzDKIJIlNuP4kEkBr3bgEFxaIthGAEhweJYRHctn8PZavQLVHXUSYobhlEESLS7lpEMLT8LeVwC\nuBjYcIqyCU1aCd/W/8aNoHtzbt8X8VLEfFG2pP/fcfHUZN/rSGQEwiZNjDeRDC1/keRKRF4BvvKt\nRYZhJDZx3n4UCfn531c9oKrXDTEMIzhIJBn540gkc2S7+d8cWRKOYe9tfjbKMIzEJXB2cOKsgm3B\n/zI0HtdIN2cahlFoSbRAlucWJTdoTXTzamdbEDMMA6IyH4kLkey1XCwiv0p+ZhhG0cSxg4vsiBen\nHFqKSIprydQKmCcia4GDOENkVdXWcWqjYRgJRqKt7M8rZs51//YHMoDewEAcU4CBPrcrT/z29OvQ\nvBHdz27NBV3a0evcszzXj4cnYRC9OUPZu3cP11w1mHM7NOe8ji1YMO8bz7Q3btxA357d6dD6TDq2\nac4zT/3LM+0cCrOvZc5kf1AyxAo47uL5FXcdUp4HmuHc+bxaVWfnVw/+5+n3yaSp1KxVi84d29G3\nb3+aNG0ai+yvePujKVSsFFtu+5MRj/aHenOmFivGyMsvotsFvahbr74n+vH4DHfffgvdul/Af156\nnWPHjnH4sHdJMVOSU7jvgUdo2ao1+/fvp1un9px73vk0buJN+/2+PvH6N5AXCdYhy7NHVllEbj7V\nEaH+E8CnqtoY5+7nqlgbXNCefrESj/YH1Zszh3379jJ39lcMumIYAMWKFaOch+nGq1WvTstWzsxI\nWloajTIae2r5V9h9LUFIivCIF3kFsmSgDJB2iiNPRKQc0BXXyklVj7kmnDERD08/ERh8SR96duvI\n+Jee91Q7Hu0PujfnhvU/UrFSZW4ZM5Je3Tpw6w3XcujgQc/0Q1m//keWLVlMm3YdPNMs7L6WQrAS\nK25R1VjMQuoB24EX3fTYC4AbVPUXv8hE87UEmDBpBtVr1GTH9m0Murg3DRpm0LFTl4JuVsQE3Zsz\nKyuL5UsXce+Dj9GqbXvuuv0Wnn7iEf54x92e1nPgwAF+N/gy/v7wY5QtW9ZT7UKNQEqCLSTL69cd\na0tTgNY06nL5AAAVMklEQVTAM6raCueO5692BKjqWFVtq6ptK6dXDisaD0+/6q6PZXrlKvTqexGL\nF87zTDtenoSXXj6U96bMYvz7Uyhbrjyn1W/ombbfn6F6jZpUr1GTVm0d98De/S9m+dLFnukDZGZm\n8rvLBzJw0GD6D7jYU+2i4GuZaD2yvAJZ9xi1NwIbVXWO+/wdnMAWE357+h06eJAD+/efePz59M/I\naOKd1Va8PAmD7M1ZpWo1qtesxdo1TiLiWV/MoGFGE8/0VZUx142kUUYTxlx/k2e6ORQNX0uJ6IgX\neTmN74pFWFV/FpENIpKhqt/iBMaVsWiC/55+27dvZfgVzj/67OwsBvxmEOeef6Fn+vHyJAyiN2co\n9z74ONdfcxWZmceoU7cejz451jPtb2bP4s3XxtO02Zl07tAGgL/e8zd69OztiX5R8LVMtLuWEfta\n5ktcpCXO8otiwDpgmKruPlV5v30tdx045ps2QMUyxXzVh+B7c1o+soLFC1/Lek2a610vfxxR2WHt\n6yaGr2UsqOpiwPcPYRhGHJHEW9kf/JSphmHEFWdlf2IFsuDckzcMI2GQCI88NURqi8gMEVkpIitE\n5Ab3fEURmSoia9y/FcK1xwKZYRhR49HyiyzgFlVtCnQERotIU5xlWtNUtSEwjQgSuVogMwwjSiLL\nRRYuH5mqblHVhe7j/ThbGGsCFwHj3GLjgAHhWmRzZIZhRIUQVQ8oXURClyKMVdVfraURkdNwUobN\nAaqq6hb3pZ+JwCPEAplhGFETxWT/jnDLL0SkDPAucKOq7gvtyamqikjYNWJFKpDVPzfSpB35Y/c8\n7/N+5cZvP8Gs7OO+6pcq7u8arBvfX+GrPsAzA5v7XkdCI3iWxlpEUnGC2Kuq+p57equIVFfVLSJS\nHdgWTsfmyAzDiIqcoWUkR546TjR8AVilqo+FvPQhMNR9PBQIm6OoSPXIDMPwBo96ZJ2AK4FlIpKT\nFeAO4EHgLREZDqwHwm4UtkBmGEbUeBHGVPWrPKSiSlphgcwwjKgQIDnBVvZbIDMMI2oSLI5ZIDMM\nI1oEiWM+/kiwQGYYRtQkWo8skMsv/PD0W/3JPcx76w6+eeM2vnr1VgCaN6rJ5+NuOXGu7Rl1Pakr\nHp6ELz77b3p1bUPvrm258ZqhHD1yxDPt60YNp17tarRv7c96qiNHjnDBOWdxTsfWdGrbggfvuydm\nzZQk4S89GnBPz4bc17sRA5o5i8W7N6zEg30zeHFwc8oU826NW6H3tQyQi1JMiEiGiCwOOfaJyI2x\n6uZ4+n3w0SQWLV3J22+8zqqVMSeeBaDnqCfoOOhBOg95GID7bxzA/WMn0XHQg/ztmY+5/8awW77C\n4mf7c/h5yyZefv5pJkz+iolfzOf48Ww+fv9tz/SHXDmUCR9O9EwvN8WLF2fCJ1P5/JuFzJw9n+mf\nTWb+3NgMerOOKw9PX8ddn67hrknf0ax6GqdXKsWaHQd5ZMY6dniYdNPv7zgev6E8iXDDeKLk7I8J\nVf1WVVuqakugDXAImBCrbjw9/VShbOkSAJQrU5It2/fGrBmv9mdlZ3HkyGGysrI4fOgQVapV90y7\nc5euVKhQ0TO93IgIZcqUARyTkMzMTE/WLR3NcnYtJCeJ6wKk/LT7CDsPZsasHUrh97UMUM5+j+kO\nrFXV9bEKnczTb+7cOXm8IzJUlY+eHoOq8sK7s/jve7P406Pv8NFTo3ngpotJShLOveofMdfjV/tD\nqVa9JsOvu5FzWmdQvGRJOp/TnS7dzve0Dr/Jzs6me+f2/LBuLVePus4T30kRuPvChlQpU4zpa3ay\nbudhD1r6a/z+juPxG8oLJ7Fi3KqLiHjNkQ0CXj/ZCyIySkTmi8j87Tu2x6k5v6b7sMc5+/KHGDDm\naa75bRc6ta7PqIFduPUf79Gw11+49dF3eeauIQXWvmjYu2c30z79mOnzVjJryVoOHzrIB++c9PIn\nLMnJycycvYCl3/7IwvnzWLViecyaqnDXp2u4+YNV1KtUiprlinvQ0qKJRPhfvPA9kIlIMaA/cNJJ\nmkTxtdzsDhu37z7Ah9OX0u6M0xjStwPvT3N2Trw7dZEnk/3x8CT8+osZ1KpTl0rplUlNTaVHn4tY\nOC+2OaaColz58nTu2o1pn03xTPNw5nFWbz3AmdXTPNMMpbD7WkIRmiMLoRewUFW3eiHmh6dfqRLF\nKFOq+InH55/VmBVrN7Nl+166tHGMbbu1b8T3P8XeY4yHJ2H1mrVYvHAehw8dQlWZ/eVM6jds7Gkd\nfrJj+3b27tkDwOHDh/l8+mc0bJQRk2Za8WRKpjo/99Rk4YxqaWzxydGpKPhaJlqPLB5zZIM5xbAy\nP/jh6VelUhpvPjbS0U9O5s1J85n69SpGH3qNR/50KSkpSRw9msWY+2L/GPHwJGzZpj09+w5gwAVn\nk5ycQtMzW/DbK6/2TH/YlZfz5Zefs3PHDjLq1+GOO+9i6LDhnulv3bqFMaOuJjs7m+PHlYsuuZQL\ne/WJSbNcyVRGdKxNkjj/COf9tIclm/dzfqNK9GpSmXIlUrm3VyOWbdnPi3M3xlRXYfe1TMQ5Mr99\nLUsDPwGnq2rYW35++1pWaDfGN22ITz6yjbv8maDOoZrP80Y5dw794o8f+r8MIcj5yLzwtWx8Zit9\n/r3pEZXt0qhiofC1PAhU8rMOwzDiT4J1yGyLkmEY0ZGIvpYWyAzDiJrECmMWyAzDyA8JFskskBmG\nETU2tDQMI/AkVhizQGYYRn5IsEhmgcwwjKgQsAyxBcnPXz9R0E2ImVoVSxZ0E2IiJdnfXXFBXqwa\nGOK8jzISilQgMwzDGxIsjlkgMwwjWsQrg17PsEBmGEbUJFgcs0BmGEZ0CDa0NAyjMJBgkcwCmWEY\nUZNoyy/M1zIXGzduoG/P7nRofSYd2zTnmaf+5ak+xMeTMOi+iqZfsPrh8CrVtYj8V0S2icjykHMV\nRWSqiKxx/1YIK6Sqvh3ATcAKYDlOltgSeZVv3bqNHs7UPI8DR7K03umn68pv1+reg0f1zDOb68Il\nK8K+73Cm6p5DWWGP1Ws36MxZc3XPoSzdsHW31m/QUL9ZsDSi90bShljaH+nhdx2mH1z91q3baKz/\nrps2b6XLNu6P6ADmh4kRXYHWwPKQcw8Dt7mPbwMeCtcmPw16awLXA21VtRmQjOOmFBN+e/pVq16d\nlq1aA5CWlkajjMZs2bzJM/14eBIG3VfR9AtWPxK8ytmvql8Au3KdvggY5z4eB4R1xvZ7aJkClBSR\nFKAUsDlWwZN5+m3a5F2gCWX9+h9ZtmSxJ56KOcSj/X7XYfqFWz8cQlRDy/Qcu0f3GBVBFVVVdYv7\n+Gegarg3+DbZr6qbRORRnJz9h4Epquqdp5fPHDhwgN8Nvoy/P/wYZcuWLejmGEZCEcVU/45Ycvar\nqopIWGMRP4eWFXC6iPWAGkBpEbniJOWiMuiNh6dfZmYmv7t8IAMHDab/gIs91Y5H+4Puq2j6Basf\nERLhkT+2ikh1APfvtnBv8HNoeT7wg6puV9VM4D3g7NyFojXo9dvTT1UZc91IGmU0Ycz1N3mmm0M8\nPAmD7qto+gWrHwlJIhEd+eRDYKj7eCgQdgLQz3VkPwEdRaQUztCyOxCz15vfnn7fzJ7Fm6+Np2mz\nM+ncoQ0Af73nb/To2dsT/Xh4EgbdV9H0C1Y/ErxaRSYirwPdcObSNgJ3AQ8Cb4nIcGA9cFlYHZ99\nLe8BfgtkAYuAEap6Sntnv30tj2Zm+6YNUDw12Vd9w4gVL3wtm7Vore9N+SqishnVShcKX8u7cCKs\nYRiFBEusaBhG8LHEioZhFAYSLI5ZIDMMI1ossaJhGIWABItjFsgMw4gOS6xoGEbhIMEimQUywzCi\nxpZfFCBHs477qh+PBbFZ2f5+Br99J/3G7+sDwb9GXmBzZIZhBBuBJAtkhmEEn8SKZBbIDMOIipzE\niomEBTLDMKImweKYBTLDMKLHemSGYQQe26JkGEbgSawwZga9pyQ7O5vundsxZGBYJ6qo8bv9140a\nTr3a1Wjfurnn2jkE3YDW72sU9OuTF5E6KMWz0+ZrIBORG0RkuYisEJEbvdDMzs7mxutH88FHk1i0\ndCVvv/E6q1au9EL6Fzz3zL9p2Kix57rxaP+QK4cy4cOJnmqG4vdnCPo1KgzXJxxe+Vp6hZ8uSs2A\nkUB7oAXQV0QaxKobD3PSzZs2MnXyJIYMvdpTXYhP+zt36UqFChU91QylMBjQ+nmNCsP1CYu/LkpR\n42ePrAkwR1UPqWoW8DlwSayi8TAn/cttt/DXex8gKcn7y1PQ5qpeUNgNaGOlKFyfBItjvgay5UAX\nEankOin1BmrnLhStr6XfTJn0CenpVWjRqnVBN8UwEpTIrOBisIOLGj+dxleJyEPAFOAgsBj4lY2R\nqo4FxoLjohRO129z0rlzvmbypI+ZNvVTjhw5woH9+/j9iKE8/fw4T/QTwlw1RoqEAW0MFPbrk4gr\n+32d7FfVF1S1jap2BXYD38Wq6bc56Z1338/i1T8wf/ka/vPieDp1PdezIAaJYa4aK0XBgDYW7PrE\nH7/vWlZx/9bBmR97LVbNUHPSlmc24TcDL4u7OWksxKP9w668nO7dOrHmu2/JqF+HcS++4Km+358h\n6NeoMFyfcCTa8gu/DXq/BCoBmcDNqjotr/J+G/TuO5zpmzZA2ZKpvuqD5SMLh+UjyxsvDHpbtW6r\nM2fNjahs+VLJhcKgt4uf+oZhFADma2kYRtBJxMl+C2SGYUSN5ew3DCPwJFqPLLizloZhFBherewX\nkZ4i8q2IfC8it+W3PRbIDMOIHg8imYgkA08BvYCmwGARaZqf5lggMwwjKgS82qLUHvheVdep6jHg\nDeCi/LQpoebIFi5csKNkqqyP4i3pwA6/2mP6hV4/HnUkmn7dWCtcuHDB5JKpkh5h8RIiEro4dKy7\nLRGgJrAh5LWNQIf8tCmhApmqVo6mvIjM93OxnekXbv141BF0/ZOhqj3jWV8k2NDSMIyCYhO/zIhT\nyz0XNRbIDMMoKOYBDUWknogUAwYBH+ZHKKGGlvlgbPgipm/6BVpH0PV9Q1WzRGQMMBlIBv6rqivy\no+XrpnHDMIx4YENLwzACjwUywzACTyADmYj8V0S2ichyH7Rri8gMEVnp2tjd4EMdJURkrogsceu4\nx4c6kkVkkYh87LW2q/+jiCwTkcW51gl5pV9eRN4RkdUiskpEzvJQO8Ntd86xzyu7wpA6bnK/2+Ui\n8rqIlPBY33OrxUCjqoE7gK5Aa2C5D9rVgdbu4zSc9NxNPa5DgDLu41RgDtDR4zpuxsnI+7FP38GP\nQLqP3/E4YIT7uBhQ3qd6koGfgboeatYEfgBKus/fAq7yUL8ZjrlPKZwbdp8BDfz6LoJwBLJHpqpf\nALt80t6iqgvdx/uBVTg/TC/rUFU94D5NdQ/P7rqISC2gD/C8V5rxRETK4fzP6gUAVT2mqnt8qq47\nsFZVo9lREgkpQEkRScEJOJs91PbFajHIBDKQxQsROQ1ohdNj8lo7WUQWA9uAqarqZR3/BG4F/Mz7\nrMAUEVkgIqM81q4HbAdedIfHz4tIaY/ryGEQ8LqXgqq6CXgU+AnYAuxV1SkeVhGR1WJRwgLZKRCR\nMsC7wI2qus9rfVXNVtWWOKuZ27vO7DEjIn2Bbaq6wAu9POisqq1xMheMFpGuHmqn4EwdPKOqrXDs\nBPOd4uVUuIsw+wNve6xbAWfzcz2gBlBaRK7wSl9VVwE5VoufcgqrxaKEBbKTICKpOEHsVVV9z8+6\n3CHTDMCr/WudgP4i8iNONoHzRGS8R9oncHsdqOo2YAJOJgOv2AhsDOmlvoMT2LymF7BQVbd6rHs+\n8IOqblfVTOA94GwvK1AfrBaDjAWyXIiI4MzNrFLVx3yqo7KIlHcflwQuAFZ7oa2qt6tqLVU9DWfY\nNF1VPesNAIhIaRFJy3kM9MAZ7niCqv4MbBCRDPdUd2ClV/ohDMbjYaXLT0BHESnl/p6648y1eoYf\nVotBJpBblETkdaAbkC4iG4G7VNUrY8JOwJXAMncOC+AOVZ3okT44d0bHuYnlkoC3VNWXZRI+URWY\n4PwbJQV4TVU/9biOPwCvusO/dcAwL8XdAHwBcI2XugCqOkdE3gEWAlnAIrzfSvSuiORYLY728WZI\nILAtSoZhBB4bWhqGEXgskBmGEXgskBmGEXgskBmGEXgskBmGEXgskAUIEcl2szUsF5G33e0p+dXq\nlpMZQ0T652WO6mai+H0+6rhbRP4Y6flcZV4SkUujqOs0P7KhGMHAAlmwOKyqLVW1GXAMuDb0RXGI\n+jtV1Q9V9cE8ipQHog5khhEvLJAFly+BBm5P5FsReRlndX1tEekhIrNFZKHbcysDJ+zpV4vIQkKy\nJYjIVSLypPu4qohMcHOlLRGRs4EHgfpub/ARt9yfRGSeiCwNzacmIn8Wke9E5CsggzCIyEhXZ4mI\nvJurl3m+iMx39fq65ZNF5JGQuj1f0GoEDwtkAcRNDdMLWOaeagg8rapn4GywvhM4393UPR+42U3s\n9xzQD2gDVDuF/L+Az1W1Bc7+xhU4G7bXur3BP4lID7fO9kBLoI2IdBWRNjjbolriZGRoF8HHeU9V\n27n1rQKGh7x2mltHH+BZ9zMMx8km0c7VHyki9SKoxyjEBHKLUhGmZMi2qS9x9oTWANar6jfu+Y5A\nU2CWu4WoGDAbaIyzkXkNgLuR/GTpd84DfgdOhg5gr5vNIZQe7rHIfV4GJ7ClARNU9ZBbRyTWXs1E\n5D6c4WsZHEedHN5S1ePAGhFZ536GHkDzkPmzcm7dRXrTdFHHAlmwOOym/jmBG6wOhp7CyW82OFe5\nX7wvRgR4QFX/k6uO/KRcfgkYoKpLROQqnD20OeTeP6du3X9Q1dCAl5M7ziii2NCy8PEN0ElEGsCJ\nTBWNcLJrnCYi9d1yg0/x/mnAde57k8XJ1rofp7eVw2Tg6pC5t5puNoYvgAEiUtLNjtEvgvamAVvc\n1ElDcr02UESS3DafDnzr1n2dWx4RaST+JV00AoL1yAoZqrrd7dm8LiLF3dN3qup34mRy/UREDuEM\nTdNOInEDMFZEhuMk67tOVWeLyCx3ecMkd56sCTDb7REeAK5Q1YUi8iawBCfz7bwImvwXnAy8292/\noW36CZgLlAWuVdUjIvI8ztzZQjdFznZgQGRXxyisWPYLwzACjw0tDcMIPBbIDMMIPBbIDMMIPBbI\nDMMIPBbIDMMIPBbIDMMIPBbIDMMIPP8Pa6kKQfmL7FoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43dbbee6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMMIPBbIDMMIPBbIDMMIPBbIDMMIPP8Pa6kKQfmL7FoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43d5e671d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_confusion_matrix(y_true_data_labels, y_final_pred_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
