{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_variant_data = pd.read_csv('training_variants')\n",
    "X_train_variant_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321\n"
     ]
    }
   ],
   "source": [
    "print X_train_variant_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACSL4</td>\n",
       "      <td>R570S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NAGLU</td>\n",
       "      <td>P521L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAH</td>\n",
       "      <td>L333F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ING1</td>\n",
       "      <td>A148D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TMEM216</td>\n",
       "      <td>G77A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Gene Variation\n",
       "0   0    ACSL4     R570S\n",
       "1   1    NAGLU     P521L\n",
       "2   2      PAH     L333F\n",
       "3   3     ING1     A148D\n",
       "4   4  TMEM216      G77A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_variant_data = pd.read_csv('test_variants')\n",
    "X_test_variant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2. This mutation resulted in a myeloproliferat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract The Large Tumor Suppressor 1 (LATS1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vascular endothelial growth factor receptor (V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Inflammatory myofibroblastic tumor (IMT) is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abstract Retinoblastoma is a pediatric retina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  2. This mutation resulted in a myeloproliferat...\n",
       "1   1   Abstract The Large Tumor Suppressor 1 (LATS1)...\n",
       "2   2  Vascular endothelial growth factor receptor (V...\n",
       "3   3  Inflammatory myofibroblastic tumor (IMT) is a ...\n",
       "4   4   Abstract Retinoblastoma is a pediatric retina..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = pd.read_table('training_text', sep='\\|\\|', engine='python', names=['ID', 'Text'], skiprows=[0])\n",
    "X_test_text = pd.read_table('test_text', sep='\\|\\|', engine='python', names=['ID', 'Text'], skiprows=[0])\n",
    "X_test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996\n"
     ]
    }
   ],
   "source": [
    "print len(np.unique(X_train_variant_data['Variation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Remove the class target label from the training variant data set and add it to an independent target label array\n",
    "\"\"\"\n",
    "y_train = X_train_variant_data['Class']\n",
    "X_train_variant_data.drop('Class', axis=1, inplace=True)\n",
    "y_train.head()\n",
    "#print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class1  class2  class3  class4  class5  class6  class7  class8  class9\n",
       "0       1       0       0       0       0       0       0       0       0\n",
       "1       0       1       0       0       0       0       0       0       0\n",
       "2       0       1       0       0       0       0       0       0       0\n",
       "3       0       0       1       0       0       0       0       0       0\n",
       "4       0       0       0       1       0       0       0       0       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    One hot encode the target label array\n",
    "\"\"\"\n",
    "\n",
    "y_train = pd.get_dummies(y_train, prefix='class', prefix_sep='')\n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 500)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Hash vectorize gene, variation columns\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "X_train_gene = X_train_variant_data['Gene']\n",
    "gene_hash_vectorizer = HashingVectorizer(n_features=500)\n",
    "gene_vector = gene_hash_vectorizer.transform(X_train_gene)\n",
    "\n",
    "X_train_variation = X_train_variant_data['Variation']\n",
    "variation_hash_vectorizer = HashingVectorizer(n_features=5000)\n",
    "variation_vector = variation_hash_vectorizer.transform(X_train_variation)\n",
    "\n",
    "X_test_gene = X_test_variant_data['Gene']\n",
    "gene_test_hash_vectorizer = HashingVectorizer(n_features=500)\n",
    "gene_test_vector = gene_test_hash_vectorizer.transform(X_test_gene)\n",
    "\n",
    "X_test_variation = X_test_variant_data['Variation']\n",
    "variation_test_hash_vectorizer = HashingVectorizer(n_features=5000)\n",
    "variation_test_vector = variation_test_hash_vectorizer.transform(X_test_variation)\n",
    "\n",
    "print gene_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection u'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/paperspace/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Download nltk stopwords corpus\n",
    "\"\"\"\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'opinion', u'guarante', u'life']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Process clinical text data by tokenizing words, removing stop words, stemming words etc.\n",
    "\"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import utils\n",
    "def process_clinical_text(clinical_text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_text = word_tokenize(utils.to_unicode(clinical_text))\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    processed_text = []\n",
    "    for word in tokenized_text:\n",
    "        if word not in stop_words:\n",
    "            processed_text.append(stemmer.stem(word))\n",
    "    return processed_text\n",
    "\n",
    "print process_clinical_text('I am of the opinion that there is no guarantee any where in life')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Method to apply doc2vec model on training and test data\n",
    "\"\"\"\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import utils\n",
    "\n",
    "def apply_doc2vec_model(processed_text):\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    epochs = 30\n",
    "\n",
    "    tagged_clinical_text = []\n",
    "\n",
    "    for i, text in processed_text.iteritems():\n",
    "        tagged_clinical_text.append(TaggedDocument(text, ['ct_' + '%s' % str(i)]))\n",
    "\n",
    "    doc2vec_model = Doc2Vec(dm=1, dm_mean=1, min_count=1, window=5, workers=cores, alpha=0.075, min_alpha=0.075)\n",
    "    doc2vec_model.build_vocab(tagged_clinical_text)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        doc2vec_model.train(tagged_clinical_text, total_examples=len(tagged_clinical_text), epochs=1)\n",
    "        doc2vec_model.alpha -= 0.002\n",
    "        doc2vec_model.min_alpha = doc2vec_model.alpha\n",
    "        \n",
    "    #clinical_text_vector = np.zeros((len(tagged_clinical_text), 300))\n",
    "    clinical_text_vector = []\n",
    "    for i in range(len(tagged_clinical_text)):\n",
    "        clinical_text_vector.append(doc2vec_model.docvecs['ct_'+str(i)])\n",
    "    \n",
    "    return clinical_text_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.61557007 -1.12856567 -2.59720778 -2.80678248 -0.48065549 -3.20750117\n",
      "  2.33187985  0.98396945  1.41099131  0.04139038  0.68676567  1.63214707\n",
      "  1.12991524  0.02724668 -2.17594433 -0.48374206 -2.64634681  0.35164991\n",
      "  2.32385182 -0.22511473  2.46642828 -0.14161544  1.67595136  1.21365917\n",
      " -0.56143421 -0.11172888  1.57000923 -2.24986625  0.66537839 -0.82744163\n",
      "  0.4604803   0.05626503  1.28072691 -0.5483433  -0.75366694  0.21033999\n",
      "  2.3632648   0.37246674 -1.53142715  1.12382329  0.84893715  0.08444068\n",
      "  0.88888896 -0.13185462  1.24280202  1.28584373 -0.01383612  2.94420218\n",
      " -0.31765664  0.79701376  1.21045458 -2.16268754  2.40276408  0.28928134\n",
      " -0.28753209 -0.58872205  2.33798671 -0.84232914 -0.3703846   3.36535907\n",
      "  1.70348263 -1.53895211  1.96951687  2.18701053 -0.15753563  1.18287182\n",
      " -0.65623903  0.56305104 -0.013279    0.60482359  1.92070258 -1.32621932\n",
      " -0.32532528 -1.57295668 -1.3812921   0.43822947  0.39770785  0.41080609\n",
      "  1.38475537  1.75631618  0.33438393 -0.9517048  -2.63668394 -0.74075603\n",
      "  0.52396309 -0.36888307 -0.23595187 -1.02114761 -3.40147686 -0.34682739\n",
      " -0.37479278 -1.04717827 -1.86762202  0.18774132 -1.97847795 -1.44176638\n",
      " -1.1596657   0.81591439 -0.86889273  0.68767887]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Apply Doc2Vec model on the clinical text training and test data\n",
    "\"\"\"\n",
    "\n",
    "processed_clinical_text = X_train_text['Text'].apply(process_clinical_text)\n",
    "#print processed_clinical_text[0]\n",
    "clinical_text_train = apply_doc2vec_model(processed_clinical_text)\n",
    "#print clinical_text_train[0]\n",
    "processed_clinical_test_text = X_test_text['Text'].apply(process_clinical_text)\n",
    "clinical_text_test = apply_doc2vec_model(processed_clinical_test_text)\n",
    "print clinical_text_test[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print clinical_text_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 5600)\n",
      "(3321, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Combine gene vector, variation vector and clinical text vector into a resultant training set\n",
    "\"\"\"\n",
    "\n",
    "X_train = np.hstack((gene_vector.toarray(), variation_vector.toarray(), clinical_text_train))\n",
    "X_test = np.hstack((gene_test_vector.toarray(), variation_test_vector.toarray(), clinical_text_test))\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 5600, 1)\n",
      "(3321, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Expand dimensions of data to fit into the CNN model\n",
    "\"\"\"\n",
    "\n",
    "X_train_dim_data = np.expand_dims(X_train, axis=2)\n",
    "print X_train_dim_data.shape\n",
    "y_train_dim_data = np.array(y_train)\n",
    "print y_train_dim_data.shape\n",
    "\n",
    "X_test_dim_data = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Define and compile the CNN model\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_cnn_model(optimizer='rmsprop'):\n",
    "    num_classes = 9\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu', input_shape=X_train_dim_data.shape[1:]))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(512, activation='relu'))\n",
    "    cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 9)\n",
      "[1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Reshape the training inputs for KFold cross validation inputs\n",
    "\"\"\"\n",
    "X_train_2d = X_train_dim_data.reshape(X_train_dim_data.shape[0], X_train_dim_data.shape[1])\n",
    "y_train_2d = y_train_dim_data.reshape(y_train_dim_data.shape[0], y_train_dim_data.shape[1])\n",
    "print y_train_2d.shape\n",
    "print y_train_2d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 5600, 64)          384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2800, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2800, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2800, 128)         41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1400, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1400, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1400, 256)         164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 700, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 179200)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               91750912  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 91,961,097\n",
      "Trainable params: 91,961,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(3321, 5600)\n",
      "(3021, 5600)\n",
      "Train on 3021 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.8415 - acc: 0.2970Epoch 00000: val_loss improved from inf to 2.05631, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "3021/3021 [==============================] - 31s - loss: 1.8418 - acc: 0.2969 - val_loss: 2.0563 - val_acc: 0.2200\n",
      "Epoch 2/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.3594 - acc: 0.5252Epoch 00001: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 1.3595 - acc: 0.5250 - val_loss: 2.8899 - val_acc: 0.1400\n",
      "Epoch 3/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 1.0441 - acc: 0.6417Epoch 00002: val_loss improved from 2.05631 to 1.96709, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "3021/3021 [==============================] - 27s - loss: 1.0443 - acc: 0.6415 - val_loss: 1.9671 - val_acc: 0.3367\n",
      "Epoch 4/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.8385 - acc: 0.7020Epoch 00003: val_loss did not improve\n",
      "3021/3021 [==============================] - 25s - loss: 0.8385 - acc: 0.7018 - val_loss: 2.9523 - val_acc: 0.2300\n",
      "Epoch 5/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.7719Epoch 00004: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.6680 - acc: 0.7719 - val_loss: 2.6807 - val_acc: 0.3500\n",
      "Epoch 6/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.8056Epoch 00005: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.5260 - acc: 0.8057 - val_loss: 3.1744 - val_acc: 0.3267\n",
      "Epoch 7/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8649Epoch 00006: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.3955 - acc: 0.8649 - val_loss: 3.2915 - val_acc: 0.2800\n",
      "Epoch 8/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.2947 - acc: 0.8990Epoch 00007: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.2946 - acc: 0.8990 - val_loss: 4.3194 - val_acc: 0.2567\n",
      "Epoch 9/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.2316 - acc: 0.9195Epoch 00008: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.2315 - acc: 0.9196 - val_loss: 4.8317 - val_acc: 0.3200\n",
      "Epoch 10/10\n",
      "3020/3021 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9513Epoch 00009: val_loss did not improve\n",
      "3021/3021 [==============================] - 26s - loss: 0.1414 - acc: 0.9513 - val_loss: 5.1968 - val_acc: 0.2333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f07324f50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Train the CNN model\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "X_valid_test = X_train_2d[:300]\n",
    "y_valid_test = y_train_2d[:300]\n",
    "X_train = X_train_2d[300:]\n",
    "y_train = y_train_2d[300:]\n",
    "\n",
    "print X_train_2d.shape\n",
    "print X_train.shape\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid_test = np.expand_dims(X_valid_test, axis=2)\n",
    "cnn_model.fit(X_train, y_train, validation_data=(X_valid_test, y_valid_test), epochs=10, batch_size=20, \n",
    "        callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Load the best weights into the model\n",
    "\"\"\"\n",
    "cnn_model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668/5668 [==============================] - 6s     \n",
      "[ 0.11251048  0.32920644  0.02660489  0.20637247  0.05765566  0.03978888\n",
      "  0.21505165  0.00667574  0.00613386]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Make predictions from test data\n",
    "\"\"\"\n",
    "\n",
    "model_predictions = cnn_model.predict_proba(X_test_dim_data)\n",
    "\n",
    "print model_predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(model_predictions)):\n",
    "    max_value = model_predictions[i][np.argmax(model_predictions[i])]\n",
    "    y_pred.append(model_predictions[i] // max_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print y_pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 2, 2, 4, 4, 4, 9, 7, 7, 7, 2, 1, 4, 1, 1, 1, 2, 3, 2, 7, 2, 1, 7, 7, 3, 7, 9, 7, 1, 4, 1, 6, 4, 9, 6, 4, 1, 5, 2, 1, 3, 2, 7, 7, 5, 7, 4, 6, 4, 1, 1, 4, 7, 1, 6, 7, 1, 1, 7, 2, 7, 2, 1, 7, 4, 9, 7, 4, 4, 1, 4, 5, 1, 1, 1, 4, 2, 2, 1, 7, 1, 5, 6, 7, 6, 6, 1, 7, 5, 2, 1, 4, 7, 7, 4, 1, 1, 4, 7, 1, 1, 2, 3, 7, 2, 2, 7, 4, 1, 4, 4, 7, 4, 7, 7, 7, 6, 3, 7, 7, 4, 4, 4, 2, 4, 1, 4, 1, 4, 1, 2, 4, 7, 7, 4, 7, 7, 7, 4, 1, 2, 7, 4, 1, 1, 7, 2, 7, 7, 7, 2, 2, 1, 4, 1, 1, 7, 7, 1, 5, 4, 4, 7, 2, 1, 2, 4, 6, 4, 7, 1, 1, 1, 1, 7, 7, 4, 5, 4, 1, 4, 2, 6, 7, 4, 5, 7, 3, 1, 7, 6, 2, 1, 8, 7, 7, 5, 7, 5, 5, 1, 1, 1, 7, 7, 2, 1, 1, 7, 1, 2, 1, 4, 9, 1, 2, 7, 7, 1, 2, 4, 1, 4, 7, 7, 1, 4, 8, 4, 5, 4, 4, 5, 1, 4, 1, 2, 7, 2, 4, 1, 6, 6, 5, 7, 7, 6, 2, 7, 9, 1, 1, 2, 6, 7, 7, 7, 1, 1, 1, 4, 5, 7, 7, 7, 2, 5, 7, 1, 6, 7, 1, 5, 5, 6, 7, 2, 1, 2, 4, 2, 7, 7, 4, 1, 5, 7, 2, 5, 6, 4, 5, 7, 5, 7, 7, 1, 7, 7, 5, 7, 3, 2, 1, 7, 6, 7, 7, 4, 1, 1, 1, 1, 1, 5, 1, 7, 1, 1, 1, 1, 2, 4, 1, 4, 4, 7, 2, 1, 1, 7, 2, 1, 1, 6, 7, 1, 6, 7, 4, 7, 7, 7, 4, 1, 7, 1, 1, 7, 1, 4, 7, 5, 2, 7, 7, 2, 7, 7, 1, 7, 4, 2, 4, 4, 6, 4, 1]\n",
      "368\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Kaggle competition test data set for target class labels are incomplete and as such our test prediction \n",
    "    and true values need to be reconciled appropriately. Setting up stage1 test data.\n",
    "\"\"\"\n",
    "y_true_data = pd.read_csv('stage1_solution_filtered.csv')\n",
    "\n",
    "y_final_pred = [y_pred[d] for d in y_true_data['ID']]\n",
    "model_predictions_final = [model_predictions[d] for d in y_true_data['ID']]\n",
    "\n",
    "y_final_pred_labels = [ np.argmax(pred) + 1 for pred in y_final_pred]\n",
    "print y_final_pred_labels[0]\n",
    "\n",
    "y_true_data.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "y_true_data_labels = [np.argmax(data) + 1 for data in np.array(y_true_data)]\n",
    "print y_true_data_labels\n",
    "\n",
    "print len(y_final_pred_labels)\n",
    "print len(y_true_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46555756129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "#print model_predictions_final\n",
    "\n",
    "#print log_loss(y_true_data_labels, model_predictions_final)\n",
    "print log_loss(np.array(y_true_data), model_predictions_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4HMMIzAY4HMMIzA8/8BpHeSXgd4DP4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f07191550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_confusion_matrix(y_true_data_labels, y_final_pred_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
